{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "add2a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de6e1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
      "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Walmart.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3bf41604",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Weekly_Sales'\n",
    "num_cols = [ 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "cat_cols = ['Store', 'Holiday_Flag']\n",
    "feature_cols = cat_cols + num_cols\n",
    "# может перевести номер филиала в категориальный признак ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b665b8",
   "metadata": {},
   "source": [
    "# что делать с DATE numerical? categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888826f",
   "metadata": {},
   "source": [
    "# Divide on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d813a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5d29018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df, columns=cat_cols)\n",
    "df = one_hot_encoded\n",
    "#df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "#df.drop(columns=cat_cols, axis=1, inplace= True)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cd3e64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = Dataset(X_tensor, y_tensor)\n",
    "\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=target_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8fa1a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "efef7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train[num_cols].mean()\n",
    "std = X_train[num_cols].std()\n",
    "\n",
    "# Standardize numerical features\n",
    "X_train[num_cols] = (X_train[num_cols] - mean) / std\n",
    "X_test[num_cols] = (X_test[num_cols] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d1d1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f78ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns='Date', axis=1, inplace= True)\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32) \n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "X_test.drop(columns='Date', axis=1, inplace= True)\n",
    "X_test =  torch.tensor(X_test.values, dtype=torch.float32) \n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc4892",
   "metadata": {},
   "source": [
    "# Sklearn LinearRegression \n",
    "проверка удалась, но теперь я не понимаю в чем проблема в нейронке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "058d0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 23934536000.0\n",
      "R^2: 0.9247692991240415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sklr = LinearRegression()\n",
    "sklr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sklr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Расчет R^2\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R^2:\", r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488c8f2",
   "metadata": {},
   "source": [
    "# NN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78946117",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7739cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Best R2: 0.9283009326389624\n",
      "Best params:\n",
      "epo 10000\n",
      "lr 10\n",
      "hiddel l size 5\n",
      "########################################\n",
      "Best R2: 0.9277044373273533\n",
      "Best params:\n",
      "epo 5000\n",
      "lr 0.04\n",
      "hiddel l size 10\n",
      "########################################\n",
      "Best R2: 0.9275681961495268\n",
      "Best params:\n",
      "epo 100\n",
      "lr 0.001\n",
      "hiddel l size 20\n",
      "########################################\n",
      "Best R2: 0.9308586227799842\n",
      "Best params:\n",
      "epo 5000\n",
      "lr 1\n",
      "hiddel l size 30\n",
      "########################################\n",
      "Best R2: 0.9277740845650989\n",
      "Best params:\n",
      "epo 1000\n",
      "lr 10\n",
      "hiddel l size 40\n",
      "########################################\n",
      "Best R2: 0.9276007102834174\n",
      "Best params:\n",
      "epo 100\n",
      "lr 10\n",
      "hiddel l size 50\n",
      "########################################\n",
      "Best R2: 0.9280220028941101\n",
      "Best params:\n",
      "epo 1000\n",
      "lr 0.4\n",
      "hiddel l size 60\n",
      "########################################\n",
      "Best R2: 0.9306941266103878\n",
      "Best params:\n",
      "epo 5000\n",
      "lr 10\n",
      "hiddel l size 70\n",
      "########################################\n",
      "Best R2: 0.9278286081672832\n",
      "Best params:\n",
      "epo 100\n",
      "lr 1\n",
      "hiddel l size 80\n",
      "########################################\n",
      "Best R2: 0.9281761759847832\n",
      "Best params:\n",
      "epo 1000\n",
      "lr 0.001\n",
      "hiddel l size 90\n",
      "########################################\n",
      "Best R2: 0.9306531800323272\n",
      "Best params:\n",
      "epo 1000\n",
      "lr 0.4\n",
      "hiddel l size 100\n",
      "########################################\n",
      "Best R2: 0.9294225546250414\n",
      "Best params:\n",
      "epo 1000\n",
      "lr 0.01\n",
      "hiddel l size 120\n",
      "########################################\n",
      "########################################\n",
      "########################################\n",
      "Best R2: 0.9308586227799842\n",
      "Best params:\n",
      "epo 5000\n",
      "lr 1\n",
      "hiddel l size 30\n"
     ]
    }
   ],
   "source": [
    "overallbest_hidden_seze = 5\n",
    "overallbest_epo = 0\n",
    "overallbest_lr = 0\n",
    "overallbest_r2 = -9999999\n",
    "\n",
    "for hidden_size in [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120]:\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(51, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, 1),\n",
    "    )\n",
    "\n",
    "    params = {'epo':[3, 10, 50, 100, 1000, 5000, 7000, 10_000],\n",
    "            'lr':[10, 1, 0.1, 0.4, 0.01, 0.04, 0.001]}\n",
    "\n",
    "    best_r2 = -99999\n",
    "    best_epo = 0\n",
    "    best_lr = 0\n",
    "    #epochs = 10_000\n",
    "    loss = nn.MSELoss()\n",
    "    #optimiz = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "    model.to('cuda')\n",
    "    X_test = X_test.to('cuda')\n",
    "    X_train = X_train.to('cuda')\n",
    "    y_test = y_test.to('cuda')\n",
    "    y_train = y_train.to('cuda')\n",
    "\n",
    "    num_samples = X_train.shape[0]\n",
    "    train_loss = torch.zeros_like(y_train, device='cuda')\n",
    "    train_pred = torch.zeros_like(y_train, device='cuda')\n",
    "\n",
    "    for epochs in params['epo']:\n",
    "        for lr in params['lr']:\n",
    "            optimiz = optim.Adam(model.parameters(), lr=lr)\n",
    "            for epoch in range(epochs):\n",
    "                train_pred = model(X_train)\n",
    "                train_loss = loss(train_pred, y_train)\n",
    "\n",
    "                optimiz.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimiz.step()\n",
    "\n",
    "            y_pred = model(X_test)\n",
    "\n",
    "            r_squared = r2_score(y_test.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "            if(r_squared > best_r2):\n",
    "                best_r2 = r_squared\n",
    "                best_epo = epochs\n",
    "                best_lr = lr\n",
    "\n",
    "            #print('-'*40)\n",
    "            #print(\"R^2:\", r_squared)\n",
    "            #print('epo:', epochs)\n",
    "            #print('lr:', lr)\n",
    "\n",
    "    print('#'*40)\n",
    "    print('Best R2:', best_r2)\n",
    "    print('Best params:')\n",
    "    print('epo', best_epo)\n",
    "    print('lr', best_lr)\n",
    "    print('hiddel l size', hidden_size)\n",
    "    if best_r2 > overallbest_r2:\n",
    "        overallbest_r2 = best_r2\n",
    "        overallbest_hidden_seze = hidden_size\n",
    "        overallbest_epo = best_epo\n",
    "        overallbest_lr = best_lr\n",
    "\n",
    "\n",
    "print('#'*40)\n",
    "print('#'*40)\n",
    "print('#'*40)\n",
    "print('Best R2:', overallbest_r2)\n",
    "print('Best params:')\n",
    "print('epo', overallbest_epo)\n",
    "print('lr', overallbest_lr)\n",
    "print('hiddel l size', overallbest_hidden_seze)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b16226b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "R^2: -2.8920334371267775\n",
      "epo: 3\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: -2.7571513291371352\n",
      "epo: 3\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: -2.742787499536081\n",
      "epo: 3\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: -2.6837605843576977\n",
      "epo: 3\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: -2.682254396533711\n",
      "epo: 3\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: -2.6762142165569633\n",
      "epo: 3\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: -2.676062943461138\n",
      "epo: 3\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.13225289496424053\n",
      "epo: 10\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.5494369636387185\n",
      "epo: 10\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.5670074988928295\n",
      "epo: 10\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.6169229599135093\n",
      "epo: 10\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.6181442416260343\n",
      "epo: 10\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.6230215127391137\n",
      "epo: 10\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.6231431879827213\n",
      "epo: 10\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.9276839031128323\n",
      "epo: 50\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.9286765095920372\n",
      "epo: 50\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.9287471561682082\n",
      "epo: 50\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.9288805636413225\n",
      "epo: 50\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.9288910684807584\n",
      "epo: 50\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.9288976660563996\n",
      "epo: 50\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.9288996006615692\n",
      "epo: 50\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.9291249161251934\n",
      "epo: 100\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.9288258421595523\n",
      "epo: 100\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.9286701710248499\n",
      "epo: 100\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.9283929429457012\n",
      "epo: 100\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.9283828934942421\n",
      "epo: 100\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.9283293367559121\n",
      "epo: 100\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.9283284018708807\n",
      "epo: 100\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.9269528536753228\n",
      "epo: 1000\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.9268481095631248\n",
      "epo: 1000\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.926822279117818\n",
      "epo: 1000\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.9323770644888998\n",
      "epo: 1000\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.9325459096621218\n",
      "epo: 1000\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.9331819623501058\n",
      "epo: 1000\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.9331986870790027\n",
      "epo: 1000\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.9256389229793969\n",
      "epo: 5000\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.9256936721536843\n",
      "epo: 5000\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.9241713452988071\n",
      "epo: 5000\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.9237374732970565\n",
      "epo: 5000\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.9221100376959023\n",
      "epo: 5000\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.9198375686037707\n",
      "epo: 5000\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.9196739275801606\n",
      "epo: 5000\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.9047334892586906\n",
      "epo: 7000\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.91501479420627\n",
      "epo: 7000\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.911623557019746\n",
      "epo: 7000\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.9103853227500504\n",
      "epo: 7000\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.9094479244578529\n",
      "epo: 7000\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.9086867918639765\n",
      "epo: 7000\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.9085033210358935\n",
      "epo: 7000\n",
      "lr: 0.001\n",
      "----------------------------------------\n",
      "R^2: 0.9063767836171821\n",
      "epo: 10000\n",
      "lr: 10\n",
      "----------------------------------------\n",
      "R^2: 0.9071842810917161\n",
      "epo: 10000\n",
      "lr: 1\n",
      "----------------------------------------\n",
      "R^2: 0.906513362476155\n",
      "epo: 10000\n",
      "lr: 0.1\n",
      "----------------------------------------\n",
      "R^2: 0.9058915684196658\n",
      "epo: 10000\n",
      "lr: 0.4\n",
      "----------------------------------------\n",
      "R^2: 0.9053350385397826\n",
      "epo: 10000\n",
      "lr: 0.01\n",
      "----------------------------------------\n",
      "R^2: 0.9051635761795535\n",
      "epo: 10000\n",
      "lr: 0.04\n",
      "----------------------------------------\n",
      "R^2: 0.9050804721202244\n",
      "epo: 10000\n",
      "lr: 0.001\n",
      "########################################\n",
      "Best R2: 0.9331986870790027\n",
      "Best params:\n",
      "epo 1000\n",
      "lr 0.001\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(51, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 1)\n",
    "\n",
    ")\n",
    "\n",
    "params = {'epo':[3, 10, 50, 100, 1000, 5000, 7000, 10_000],\n",
    "          'lr':[10, 1, 0.1, 0.4, 0.01, 0.04, 0.001]}\n",
    "\n",
    "best_r2 = -99999\n",
    "best_epo = 0\n",
    "best_lr = 0\n",
    "#epochs = 10_000\n",
    "loss = nn.MSELoss()\n",
    "#optimiz = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "model.to('cuda')\n",
    "X_test = X_test.to('cuda')\n",
    "X_train = X_train.to('cuda')\n",
    "y_test = y_test.to('cuda')\n",
    "y_train = y_train.to('cuda')\n",
    "\n",
    "num_samples = X_train.shape[0]\n",
    "train_loss = torch.zeros_like(y_train, device='cuda')\n",
    "train_pred = torch.zeros_like(y_train, device='cuda')\n",
    "\n",
    "for epochs in params['epo']:\n",
    "    for lr in params['lr']:\n",
    "        optimiz = optim.Adam(model.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            train_pred = model(X_train)\n",
    "            train_loss = loss(train_pred, y_train)\n",
    "\n",
    "            optimiz.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimiz.step()\n",
    "\n",
    "        y_pred = model(X_test)\n",
    "\n",
    "        r_squared = r2_score(y_test.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "        if(r_squared > best_r2):\n",
    "            best_r2 = r_squared\n",
    "            best_epo = epochs\n",
    "            best_lr = lr\n",
    "\n",
    "        print('-'*40)\n",
    "        print(\"R^2:\", r_squared)\n",
    "        print('epo:', epochs)\n",
    "        print('lr:', lr)\n",
    "\n",
    "print('#'*40)\n",
    "print('Best R2:', best_r2)\n",
    "print('Best params:')\n",
    "print('epo', best_epo)\n",
    "print('lr', best_lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a022c5",
   "metadata": {},
   "source": [
    "# CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "003678ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9291178999855932\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(51, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 1)\n",
    ")\n",
    "\n",
    "epochs = 10_000\n",
    "batch_size = 256\n",
    "loss = nn.MSELoss()\n",
    "optimiz = optim.Adam(model.parameters(), lr=0.1)\n",
    "mydevice = 'cpu'\n",
    "\n",
    "\n",
    "model.to(mydevice)\n",
    "X_test = X_test.to(mydevice)\n",
    "X_train = X_train.to(mydevice)\n",
    "y_test = y_test.to(mydevice)\n",
    "y_train = y_train.to(mydevice)\n",
    "\n",
    "num_samples = X_train.shape[0]\n",
    "train_loss = torch.zeros_like(y_train, device=mydevice)\n",
    "train_pred = torch.zeros_like(y_train, device=mydevice)\n",
    "for epoch in range(epochs):\n",
    "    train_pred = model(X_train)\n",
    "    train_loss = loss(train_pred, y_train)\n",
    "\n",
    "    optimiz.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimiz.step()\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "r_squared = r2_score(y_test.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "\n",
    "print(\"R^2:\", r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

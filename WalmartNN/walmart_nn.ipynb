{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add2a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6e1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
      "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Walmart.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf41604",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Weekly_Sales'\n",
    "num_cols = [ 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "cat_cols = ['Store', 'Holiday_Flag']\n",
    "feature_cols = cat_cols + num_cols\n",
    "# может перевести номер филиала в категориальный признак ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b665b8",
   "metadata": {},
   "source": [
    "# что делать с DATE numerical? categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888826f",
   "metadata": {},
   "source": [
    "# Divide on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d813a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d29018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df, columns=cat_cols)\n",
    "df = one_hot_encoded\n",
    "#df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "#df.drop(columns=cat_cols, axis=1, inplace= True)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd3e64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = Dataset(X_tensor, y_tensor)\n",
    "\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=target_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97504f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X)\n",
    "#mean = df[num_cols].mean()\n",
    "#std = df[num_cols].std()\n",
    "\n",
    "# Standardize numerical features\n",
    "#df[num_cols] = (df[num_cols] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fa1a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efef7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train[num_cols].mean()\n",
    "std = X_train[num_cols].std()\n",
    "\n",
    "# Standardize numerical features\n",
    "X_train[num_cols] = (X_train[num_cols] - mean) / std\n",
    "X_test[num_cols] = (X_test[num_cols] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d1d1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns='Date', axis=1, inplace= True)\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32) \n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "X_test.drop(columns='Date', axis=1, inplace= True)\n",
    "X_test =  torch.tensor(X_test.values, dtype=torch.float32) \n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc4892",
   "metadata": {},
   "source": [
    "# Sklearn LinearRegression \n",
    "проверка удалась, но теперь я не понимаю в чем проблема в нейронке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058d0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 31261008000.0\n",
      "R^2: 0.9041265019592664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sklr = LinearRegression()\n",
    "sklr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sklr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Расчет R^2\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R^2:\", r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488c8f2",
   "metadata": {},
   "source": [
    "# NN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e02127ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyNNRegr(object):\n",
    "    def __init__(self, model, optim, epochs = 3, loss = nn.MSELoss(), batch_size = 256):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epochs = epochs\n",
    "        self.loss = loss\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print('1st ',X.shape, y.shape)\n",
    "        \n",
    "        \n",
    "        num_samples = X.shape[0]\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            '''for i in range(num_samples):\n",
    "                X_line = X[i]\n",
    "                y_line = y[i]\n",
    "                #print(X_line, y_line)\n",
    "                train_pred = self.model(X_line)\n",
    "                train_loss = self.loss(train_pred, y_line)\n",
    "                print(train_pred, y_line)\n",
    "                #print('loss: ', train_loss)\n",
    "                #print('2nd', train_pred.shape, y_line.shape)\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optim.step()'''\n",
    "            for param in model.parameters():\n",
    "                print(param)\n",
    "            shuffled_indices = np.random.permutation(num_samples)\n",
    "            \n",
    "            for batch_start in range(0, num_samples, self.batch_size):\n",
    "                batch_indices = shuffled_indices[batch_start:batch_start+self.batch_size]\n",
    "                batch_X = X[batch_indices]\n",
    "                batch_y = y[batch_indices]\n",
    "\n",
    "\n",
    "                train_pred = self.model(batch_X)\n",
    "                train_loss = self.loss(train_pred, batch_y)\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(X)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6b0be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(51, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 1)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "mynn = MyNNRegr(model, optimizer, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f6c6b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st  torch.Size([5148, 51]) torch.Size([5148, 1])\n",
      "Parameter containing:\n",
      "tensor([[-0.0675, -0.0194,  0.0466,  ...,  0.0779,  0.1356,  0.1236],\n",
      "        [ 0.0062, -0.0357, -0.0692,  ...,  0.1092,  0.1125, -0.1031],\n",
      "        [-0.1206, -0.0438,  0.0997,  ...,  0.0125,  0.0305,  0.0632],\n",
      "        ...,\n",
      "        [ 0.1291,  0.1225,  0.0035,  ...,  0.1342, -0.0220,  0.0986],\n",
      "        [ 0.0214,  0.0122,  0.0917,  ..., -0.0566,  0.0654,  0.1215],\n",
      "        [-0.0464,  0.0950,  0.0010,  ...,  0.1152, -0.0255, -0.0798]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1149,  0.0339, -0.0298,  0.1140,  0.1247,  0.0428,  0.1081,  0.1295,\n",
      "        -0.1083, -0.0053, -0.0654,  0.0921, -0.0279,  0.0051, -0.0661, -0.0590,\n",
      "        -0.1392,  0.0021, -0.1036, -0.0697,  0.1214, -0.0772, -0.0061,  0.0238,\n",
      "        -0.1068,  0.0370,  0.0535, -0.0491, -0.0964, -0.0306,  0.1063,  0.0231,\n",
      "        -0.0034,  0.0827,  0.0292,  0.0260,  0.0217,  0.0171, -0.0878, -0.0171,\n",
      "         0.1240, -0.0410, -0.0561,  0.1222,  0.1057, -0.1106, -0.0829, -0.0737,\n",
      "         0.1363,  0.1295, -0.0580, -0.0765,  0.1052, -0.0427,  0.0478,  0.0936,\n",
      "         0.0949,  0.1328, -0.0302,  0.1068], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0123, -0.0788, -0.1162,  0.0511,  0.0880, -0.0033,  0.0157, -0.0127,\n",
      "         -0.0333,  0.1249, -0.0982, -0.0969, -0.0136, -0.0231,  0.0499,  0.1191,\n",
      "         -0.1194, -0.1079,  0.0230,  0.0462,  0.0079, -0.0525, -0.0579,  0.0863,\n",
      "         -0.0051,  0.0452,  0.1239, -0.0989,  0.1211, -0.1249, -0.1011,  0.0619,\n",
      "          0.0186,  0.0529,  0.1070, -0.0821,  0.0847,  0.0886,  0.1055,  0.0989,\n",
      "         -0.1083,  0.0601,  0.1138,  0.0666, -0.0993, -0.0474,  0.0206,  0.0227,\n",
      "          0.0457, -0.0895,  0.1082, -0.0723, -0.0435,  0.0566, -0.0997, -0.0400,\n",
      "         -0.0239,  0.0301,  0.0167, -0.0951]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0090], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[        nan,         nan,         nan,  ...,         nan,\n",
      "                 nan,         nan],\n",
      "        [ 6.1839e-01,  1.1117e+00,  1.0496e+00,  ..., -3.0568e-01,\n",
      "         -1.1836e+01, -5.7383e-01],\n",
      "        [        nan,         nan,         nan,  ...,         nan,\n",
      "                 nan,         nan],\n",
      "        ...,\n",
      "        [-2.5824e+07, -3.3698e+07,  2.9995e+07,  ..., -5.3281e+06,\n",
      "         -2.1236e+08, -1.0336e+07],\n",
      "        [-1.2388e+07, -1.6166e+07,  1.4389e+07,  ..., -2.5560e+06,\n",
      "         -1.0187e+08, -4.9585e+06],\n",
      "        [ 3.6801e+00, -3.2826e+00, -1.2280e-01,  ..., -3.8530e-01,\n",
      "         -1.4596e+01, -1.1665e+00]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([        nan, -1.2385e+01,         nan, -4.5427e+08, -5.3943e+08,\n",
      "        -5.4297e-01, -1.4473e+08,         nan,         nan, -4.2837e+08,\n",
      "                nan,         nan,         nan,         nan, -2.4741e+08,\n",
      "        -4.0872e+08,         nan,         nan, -3.9809e+07, -2.7275e+08,\n",
      "        -8.0042e+07, -2.3892e+06, -8.0602e+00, -6.3805e+08,         nan,\n",
      "        -3.5027e+08, -9.1314e+08,         nan, -6.6848e+08,         nan,\n",
      "        -1.4536e+01, -5.1093e+08, -6.2272e+07, -3.1483e+08, -4.5042e+08,\n",
      "                nan, -5.8613e+08, -5.3998e+08, -3.7819e+08, -3.2169e+08,\n",
      "        -1.7866e+01, -1.3750e+08, -6.6202e+07, -4.7776e+08, -1.5578e+01,\n",
      "                nan, -3.5054e+07, -9.9087e+07, -3.0045e+08, -1.6195e+01,\n",
      "        -1.7832e+08,         nan, -7.2559e+00, -1.2992e+08,         nan,\n",
      "        -5.9481e+00, -2.8949e+00, -2.2269e+08, -1.0683e+08, -1.5550e+01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]])\n",
      "tensor([[ 422093.5938],\n",
      "        [ 640210.8750],\n",
      "        [ 294264.1875],\n",
      "        [ 578002.8750],\n",
      "        [1024784.9375]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(y_pred[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(y_test[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMean Squared Error (MSE):\u001b[39m\u001b[39m\"\u001b[39m, mse)\n\u001b[0;32m     12\u001b[0m \u001b[39m# Расчет R^2\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 102\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mynn.fit(X_train, y_train)\n",
    "y_pred = mynn.predict(X_test)\n",
    "\n",
    "print(y_pred[0:5])\n",
    "print(y_test[0:5])\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Расчет R^2\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R^2:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfa01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

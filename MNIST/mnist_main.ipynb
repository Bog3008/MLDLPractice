{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19845013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80b01a",
   "metadata": {},
   "source": [
    "# Downloading and preprocessing MNIST ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fff0ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Преобразования для нормализации изображений\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))]) \n",
    "\n",
    "# Загрузка обучающего и тестового наборов данных MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea3667",
   "metadata": {},
   "source": [
    "Тут возник вопрос, как праильно вычислять mean и std:\n",
    "По всему data set'у или в каждом изображении/батче отдельно?\n",
    "\n",
    "значения 0.5 и 0.5 были взяты из интернета, когда я гуглил про то, как скачать mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ff8ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size: 60000 \n",
      " Test data set size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Train data set size:', len(train_dataset),'\\n', 'Test data set size:', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538973c",
   "metadata": {},
   "source": [
    "## Making a Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a38a8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f34ef6",
   "metadata": {},
   "source": [
    "## Transfer to CUDA if it is available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0182d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device for running and trainning: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Current device for running and trainning:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a61071",
   "metadata": {},
   "source": [
    "Я юы хотел перенести dataset или dataloader сразу все данные, но попытки были безуспешны.\n",
    "\n",
    "Как можно перенести данные на cuda до начала цикла обучения ?\n",
    "\n",
    "там не так много данных и я могу себе позволить перенести весь датасет на видеокарту "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45216d1e",
   "metadata": {},
   "source": [
    "я не знаю как inplace изменить dataset или dataloader что бы применить one hot и labels. Придется каждый раз считать это в цикле обучения("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25273a6e",
   "metadata": {},
   "source": [
    "# Model creating and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6979521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa9f347",
   "metadata": {},
   "source": [
    "входное изображение 28х28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4592011b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img, label = train_dataset[0]\n",
    "test_img = test_img.squeeze()  # Убираем размерность канала, если она равна 1\n",
    "\n",
    "# Вывод изображения с помощью Matplotlib\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.title(f\"Digit: {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf119ccc",
   "metadata": {},
   "source": [
    "обучающая функция\n",
    "\n",
    "вынес ее отдельно тк она общая для каждой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "69d72cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_size = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            \n",
    "            total_size += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "    #print(\"Accuracy:\", correct / total_size)\n",
    "    #print('True predicted', correct, '/', total_size)\n",
    "        return correct, total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "302ead03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "num_classes = 10 # from 0 to 9\n",
    "\n",
    "#labels = torch.empty(batch_size, num_classes, )\n",
    "#labels = labels.to(device)\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = torch.eye(num_classes).to(device)[labels]#.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            correct, total_size = evaluate_model(model, test_loader)\n",
    "            print(\"\\tAccuracy:\", correct / total_size)\n",
    "            #print('True predicted', correct, '/', total_size)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9d87a",
   "metadata": {},
   "source": [
    "## Ordinary model\n",
    "попробуем без Dropout, Batchnorm и Skipconnection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0c76f",
   "metadata": {},
   "source": [
    "этот кусок кода я скопировал из книжки и немного дополнил - one hot encoding для lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bfa14d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 17:34:25 Epoch 1, Training loss 1.089393458513817\n",
      "\tAccuracy: 0.897\n",
      "2023-08-25 17:36:13 Epoch 10, Training loss 0.06659484190542672\n",
      "\tAccuracy: 0.9826\n",
      "2023-08-25 17:38:18 Epoch 20, Training loss 0.040947373791623595\n",
      "\tAccuracy: 0.9857\n",
      "2023-08-25 17:40:18 Epoch 30, Training loss 0.03044464245001956\n",
      "\tAccuracy: 0.9882\n",
      "2023-08-25 17:42:18 Epoch 40, Training loss 0.02358030447807001\n",
      "\tAccuracy: 0.9885\n",
      "2023-08-25 17:44:21 Epoch 50, Training loss 0.01897390819630518\n",
      "\tAccuracy: 0.9894\n",
      "2023-08-25 17:46:21 Epoch 60, Training loss 0.015030871789318449\n",
      "\tAccuracy: 0.9892\n",
      "2023-08-25 17:48:21 Epoch 70, Training loss 0.012116988112872677\n",
      "\tAccuracy: 0.9888\n",
      "2023-08-25 17:50:24 Epoch 80, Training loss 0.009551386542041846\n",
      "\tAccuracy: 0.9883\n",
      "2023-08-25 17:52:23 Epoch 90, Training loss 0.007643287306517621\n",
      "\tAccuracy: 0.9888\n",
      "2023-08-25 17:54:24 Epoch 100, Training loss 0.005937199195808007\n",
      "\tAccuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "conv1_out_ch = 16\n",
    "conv2_out_ch = 8\n",
    "kernel_size = 3\n",
    "\n",
    "ordinary_model = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(conv1_out_ch, conv2_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8 * 7 * 7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10))\n",
    "\n",
    "ordinary_model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(ordinary_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "training_loop(n_epochs, optimizer, ordinary_model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fa93ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9861\n",
      "True predicted 9861 / 10000\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ordinary_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35285a3c",
   "metadata": {},
   "source": [
    "Даже обычная сверточная модел без Dropout, Batchnorm и Skipconnection справилась на этом датасете неплохо(хотя и датасет простой)\n",
    "\n",
    "1st Test:  \n",
    "Точность: 98.74%  \n",
    "Праильно: 9874 / 10_000  \n",
    "\n",
    "2nd Test:  \n",
    "Точность: 98.61%  \n",
    "Праильно: 9861 / 10_000  \n",
    "из-за своего косяка мне пришлось дважды обучить модель, поэтому тут два теста\n",
    "\n",
    "3rd Test:\n",
    "Точность: 98.89%  \n",
    "Праильно: 9898 / 10_000  \n",
    "лучший результат достигается в самом конце"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6471c0",
   "metadata": {},
   "source": [
    "Тут возникает вопрос, стоит ли улучшать модель, тк улучшения могут быть и не особо заметны, но почему бы и нет "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dced409",
   "metadata": {},
   "source": [
    "## Ordinary model + Tanh\n",
    "Хочу протестировать с другой функцией активации \n",
    "\n",
    "Заменим все ReLU на Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7a44f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 18:04:31 Epoch 1, Training loss 1.3120998711601248\n",
      "\tAccuracy: 0.8668\n",
      "2023-08-25 18:06:19 Epoch 10, Training loss 0.11606150145517356\n",
      "\tAccuracy: 0.9707\n",
      "2023-08-25 18:08:23 Epoch 20, Training loss 0.0729654192987051\n",
      "\tAccuracy: 0.979\n",
      "2023-08-25 18:10:22 Epoch 30, Training loss 0.05647478429382163\n",
      "\tAccuracy: 0.9829\n",
      "2023-08-25 18:12:22 Epoch 40, Training loss 0.04732624837296651\n",
      "\tAccuracy: 0.9843\n",
      "2023-08-25 18:14:26 Epoch 50, Training loss 0.040922385865329966\n",
      "\tAccuracy: 0.9853\n",
      "2023-08-25 18:16:25 Epoch 60, Training loss 0.03634378703873056\n",
      "\tAccuracy: 0.986\n",
      "2023-08-25 18:18:26 Epoch 70, Training loss 0.032778651035551644\n",
      "\tAccuracy: 0.9869\n",
      "2023-08-25 18:20:29 Epoch 80, Training loss 0.02968440427959188\n",
      "\tAccuracy: 0.9876\n",
      "2023-08-25 18:22:28 Epoch 90, Training loss 0.027158318939474797\n",
      "\tAccuracy: 0.9868\n",
      "2023-08-25 18:24:29 Epoch 100, Training loss 0.024912030065629774\n",
      "\tAccuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9872, 10000)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_out_ch = 16\n",
    "conv2_out_ch = 8\n",
    "kernel_size = 3\n",
    "\n",
    "model_tanh = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(conv1_out_ch, conv2_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8 * 7 * 7, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 10))\n",
    "\n",
    "model_tanh.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model_tanh.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "training_loop(n_epochs, optimizer, model_tanh, loss_fn, train_loader)\n",
    "\n",
    "evaluate_model(model_tanh, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396aa3e",
   "metadata": {},
   "source": [
    "Ну чет разницы вообще почти нет, на 2 стоые лучше чем у предыдущей модели те текущая модель предсказала правильно на 2 картики больше \n",
    "\n",
    "1st Test:  \n",
    "Точность: 98.76%  \n",
    "Праильно: 9876 / 10_000  \n",
    "\n",
    "2nd Test:  \n",
    "Точность: 98.72%  \n",
    "Праильно: 9872 / 10_000  \n",
    "после 80ой эпохи результат на 4 сотые процента лучше, скорее погрешность \n",
    "\n",
    "Так же я ожидал что она будет работать дольше, тк слышал из лекций, но и чисто логически понятно, что производная ReLU намного проще считается. \n",
    "Однако тут все же есть разница ~10 секунд дольше иногда для 10 эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80225596",
   "metadata": {},
   "source": [
    "## Ordinary model + Adam\n",
    "Заменим SGD на Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5a606087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 18:24:45 Epoch 1, Training loss 0.18735437904959168\n",
      "\tAccuracy: 0.9722\n",
      "2023-08-25 18:26:35 Epoch 10, Training loss 0.07436344940163223\n",
      "\tAccuracy: 0.9779\n",
      "2023-08-25 18:28:35 Epoch 20, Training loss 0.06704386312204019\n",
      "\tAccuracy: 0.9756\n",
      "2023-08-25 18:30:38 Epoch 30, Training loss 0.06595333824544819\n",
      "\tAccuracy: 0.9708\n",
      "2023-08-25 18:32:44 Epoch 40, Training loss 0.06569145562139396\n",
      "\tAccuracy: 0.975\n",
      "2023-08-25 18:34:43 Epoch 50, Training loss 0.06226704582299686\n",
      "\tAccuracy: 0.9761\n",
      "2023-08-25 18:36:47 Epoch 60, Training loss 0.060985493739583604\n",
      "\tAccuracy: 0.9752\n",
      "2023-08-25 18:38:51 Epoch 70, Training loss 0.062163011309166905\n",
      "\tAccuracy: 0.978\n",
      "2023-08-25 18:40:51 Epoch 80, Training loss 0.057178736665409735\n",
      "\tAccuracy: 0.9773\n",
      "2023-08-25 18:42:56 Epoch 90, Training loss 0.06171750899887138\n",
      "\tAccuracy: 0.9758\n",
      "2023-08-25 18:44:59 Epoch 100, Training loss 0.06370039359106484\n",
      "\tAccuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9727, 10000)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_out_ch = 16\n",
    "conv2_out_ch = 8\n",
    "kernel_size = 3\n",
    "\n",
    "adam_model = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(conv1_out_ch, conv2_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8 * 7 * 7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10))\n",
    "\n",
    "adam_model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.Adam(adam_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "training_loop(n_epochs, optimizer, adam_model, loss_fn, train_loader)\n",
    "\n",
    "\n",
    "evaluate_model(adam_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d42aa",
   "metadata": {},
   "source": [
    "Adam сразу начал с низким Training loss'ом по сравнению с предыдущими моделями\n",
    "\n",
    "Возможно на 40й эпохе нужно остановить. Нужно каждые 10 эпох проверять на тестовом датасете и выводить данные, проверка занимает не много времени. Обидно, как я раньше не додумался - теперь нужно будет перезапускачть все модели, что бы посмотреть на изменения точности на тесте. Для этого нужно дополнить функцию evaluate_model\n",
    "\n",
    "1st Test:  \n",
    "Точность: 97.43%  \n",
    "Праильно: 9743 / 10_000    \n",
    "Точность хуже, чем у предыдущих примерно на процент те на 100 неверных ответов больше \n",
    "\n",
    "2тв Test:  \n",
    "Точность: 97.27%  \n",
    "Праильно: 9727 / 10_000  \n",
    "Как я и предполагал тут быстро происходит насыщение. и после 70ой эпохи точность падает на 6 десятых процента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb39c6",
   "metadata": {},
   "source": [
    "## Ordinary model + DropOut\n",
    "Добавим DropOut в обычную модель (с ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef36169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 18:45:14 Epoch 1, Training loss 1.3749489463023794\n",
      "\tAccuracy: 0.8773\n",
      "2023-08-25 18:47:01 Epoch 10, Training loss 0.0749382493840749\n",
      "\tAccuracy: 0.9788\n",
      "2023-08-25 18:49:01 Epoch 20, Training loss 0.046964089866223205\n",
      "\tAccuracy: 0.9822\n",
      "2023-08-25 18:51:01 Epoch 30, Training loss 0.03534409180297199\n",
      "\tAccuracy: 0.9851\n",
      "2023-08-25 18:52:59 Epoch 40, Training loss 0.028374327570825482\n",
      "\tAccuracy: 0.9867\n",
      "2023-08-25 18:54:58 Epoch 50, Training loss 0.02277248651998714\n",
      "\tAccuracy: 0.9875\n",
      "2023-08-25 18:56:58 Epoch 60, Training loss 0.018946958165965786\n",
      "\tAccuracy: 0.9868\n",
      "2023-08-25 18:58:55 Epoch 70, Training loss 0.016052112233962978\n",
      "\tAccuracy: 0.9871\n",
      "2023-08-25 19:00:55 Epoch 80, Training loss 0.013304501076941061\n",
      "\tAccuracy: 0.9869\n",
      "2023-08-25 19:02:55 Epoch 90, Training loss 0.011527001280668636\n",
      "\tAccuracy: 0.9868\n",
      "2023-08-25 19:04:53 Epoch 100, Training loss 0.009874266363403722\n",
      "\tAccuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9864, 10000)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_out_ch = 16\n",
    "conv2_out_ch = 8\n",
    "kernel_size = 3\n",
    "\n",
    "dropout_model = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Dropout(p=0.3), # 1st dropout\n",
    "\n",
    "            nn.Conv2d(conv1_out_ch, conv2_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Dropout(p=0.3), # 2nd dropout\n",
    "\n",
    "            nn.Linear(8 * 7 * 7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10))\n",
    "\n",
    "dropout_model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(dropout_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "training_loop(n_epochs, optimizer, dropout_model, loss_fn, train_loader)\n",
    "\n",
    "\n",
    "evaluate_model(dropout_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38e194",
   "metadata": {},
   "source": [
    "С р=0.3 результат не особо лучше обычной модели, возможно имеет смысл попробовать р побольше, но я боюсь, что из за наложения на начальных слоях останется мало нейронов\n",
    "\n",
    "\n",
    "1st Test:  \n",
    "Точность: 98.64%  \n",
    "Праильно: 9764 / 10_000  \n",
    "Тоже относительно быстро происходит насыщение лучший результат - 98.75% на 50ой эпохе "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3567d",
   "metadata": {},
   "source": [
    "## Ordinary model + BatchNorm\n",
    "Добавим BatchNorm в обычную модель (с ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d74166e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 19:05:09 Epoch 1, Training loss 0.389585454191671\n",
      "\tAccuracy: 0.9738\n",
      "2023-08-25 19:07:01 Epoch 10, Training loss 0.027030378143566954\n",
      "\tAccuracy: 0.9853\n",
      "2023-08-25 19:09:05 Epoch 20, Training loss 0.012746241657109721\n",
      "\tAccuracy: 0.989\n",
      "2023-08-25 19:11:07 Epoch 30, Training loss 0.005298139848686593\n",
      "\tAccuracy: 0.9875\n",
      "2023-08-25 19:13:12 Epoch 40, Training loss 0.0020841108131474033\n",
      "\tAccuracy: 0.9881\n",
      "2023-08-25 19:15:15 Epoch 50, Training loss 0.0005142504325329684\n",
      "\tAccuracy: 0.9885\n",
      "2023-08-25 19:17:17 Epoch 60, Training loss 0.00023568552932081774\n",
      "\tAccuracy: 0.9881\n",
      "2023-08-25 19:19:22 Epoch 70, Training loss 0.0001606414651027439\n",
      "\tAccuracy: 0.9881\n",
      "2023-08-25 19:21:25 Epoch 80, Training loss 0.00012169297149120584\n",
      "\tAccuracy: 0.9882\n",
      "2023-08-25 19:23:29 Epoch 90, Training loss 9.596177190213616e-05\n",
      "\tAccuracy: 0.9882\n",
      "2023-08-25 19:25:35 Epoch 100, Training loss 7.95941465593971e-05\n",
      "\tAccuracy: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9881, 10000)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_out_ch = 16\n",
    "conv2_out_ch = 8\n",
    "kernel_size = 3\n",
    "\n",
    "batchnorm_model = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.BatchNorm2d( conv1_out_ch ), # 1st BatchNorm\n",
    "\n",
    "            nn.Conv2d(conv1_out_ch, conv2_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.BatchNorm2d( conv2_out_ch ), # 2nd BatchNorm\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8 * 7 * 7, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(32),\n",
    "\n",
    "            nn.Linear(32, 10))\n",
    "\n",
    "batchnorm_model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(batchnorm_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "training_loop(n_epochs, optimizer, batchnorm_model, loss_fn, train_loader)\n",
    "\n",
    "\n",
    "evaluate_model(batchnorm_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa1d74",
   "metadata": {},
   "source": [
    "Данная модель, наверное, показала самый лучший результат за обучение на 1ой эпохе\n",
    "1st Test:  \n",
    "Точность: 98.81%  \n",
    "Праильно: 9781 / 10_000  \n",
    "Лучший результат - 98.9 на 20ой эпохе "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007a12f",
   "metadata": {},
   "source": [
    "## Ordinary model + DropOut с р=0.5\n",
    "Добавим DropOut в обычную модель (с ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5cc1e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 21:04:27 Epoch 1, Training loss 1.6435622435007522\n",
      "\tAccuracy: 0.85\n",
      "2023-08-25 21:06:18 Epoch 10, Training loss 0.07603409568936045\n",
      "\tAccuracy: 0.9772\n",
      "2023-08-25 21:08:18 Epoch 20, Training loss 0.04785958005498642\n",
      "\tAccuracy: 0.9827\n",
      "2023-08-25 21:10:18 Epoch 30, Training loss 0.03649413306129548\n",
      "\tAccuracy: 0.9861\n",
      "2023-08-25 21:12:19 Epoch 40, Training loss 0.02940039316594138\n",
      "\tAccuracy: 0.9873\n",
      "2023-08-25 21:14:18 Epoch 50, Training loss 0.0243110539829001\n",
      "\tAccuracy: 0.9874\n",
      "2023-08-25 21:16:18 Epoch 60, Training loss 0.02037262030216783\n",
      "\tAccuracy: 0.9892\n",
      "2023-08-25 21:18:20 Epoch 70, Training loss 0.017299349098544525\n",
      "\tAccuracy: 0.9884\n",
      "2023-08-25 21:20:19 Epoch 80, Training loss 0.014734179160084146\n",
      "\tAccuracy: 0.9878\n",
      "2023-08-25 21:22:19 Epoch 90, Training loss 0.012330567270403416\n",
      "\tAccuracy: 0.9888\n",
      "2023-08-25 21:24:20 Epoch 100, Training loss 0.01025273425365236\n",
      "\tAccuracy: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9885, 10000)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conv1_out_ch = 16\n",
    "conv2_out_ch = 8\n",
    "kernel_size = 3\n",
    "\n",
    "dropout05_model = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Dropout(p=0.5), # 1st dropout\n",
    "\n",
    "            nn.Conv2d(conv1_out_ch, conv2_out_ch, kernel_size=kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Dropout(p=0.5), # 2nd dropout\n",
    "\n",
    "            nn.Linear(8 * 7 * 7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10))\n",
    "\n",
    "dropout05_model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(dropout05_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "training_loop(n_epochs, optimizer, dropout05_model, loss_fn, train_loader)\n",
    "\n",
    "\n",
    "evaluate_model(dropout05_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
